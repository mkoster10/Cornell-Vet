{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3ea7f75",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-12T04:16:10.842186Z",
     "iopub.status.busy": "2023-05-12T04:16:10.841715Z",
     "iopub.status.idle": "2023-05-12T04:16:13.110133Z",
     "shell.execute_reply": "2023-05-12T04:16:13.108921Z"
    },
    "papermill": {
     "duration": 2.279122,
     "end_time": "2023-05-12T04:16:13.112823",
     "exception": false,
     "start_time": "2023-05-12T04:16:10.833701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/cs4780-spring-2023-kaggle-competition/sample_submission.csv\n",
      "/kaggle/input/cs4780-spring-2023-kaggle-competition/LH_train.csv\n",
      "/kaggle/input/cs4780-spring-2023-kaggle-competition/LF_test.csv\n",
      "/kaggle/input/cs4780-spring-2023-kaggle-competition/LF_train.csv\n",
      "/kaggle/input/cs4780-spring-2023-kaggle-competition/RF_test.csv\n",
      "/kaggle/input/cs4780-spring-2023-kaggle-competition/RH_test.csv\n",
      "/kaggle/input/cs4780-spring-2023-kaggle-competition/General info for Killian.pptx\n",
      "/kaggle/input/cs4780-spring-2023-kaggle-competition/LH_test.csv\n",
      "/kaggle/input/cs4780-spring-2023-kaggle-competition/RH_train.csv\n",
      "/kaggle/input/cs4780-spring-2023-kaggle-competition/form_prediction.py\n",
      "/kaggle/input/cs4780-spring-2023-kaggle-competition/RF_train.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "875f17d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T04:16:13.127295Z",
     "iopub.status.busy": "2023-05-12T04:16:13.126046Z",
     "iopub.status.idle": "2023-05-12T04:16:13.345368Z",
     "shell.execute_reply": "2023-05-12T04:16:13.344092Z"
    },
    "papermill": {
     "duration": 0.229552,
     "end_time": "2023-05-12T04:16:13.348373",
     "exception": false,
     "start_time": "2023-05-12T04:16:13.118821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LF_training = pd.read_csv(\"/kaggle/input/cs4780-spring-2023-kaggle-competition/LF_train.csv\")\n",
    "LH_training = pd.read_csv(\"/kaggle/input/cs4780-spring-2023-kaggle-competition/LH_train.csv\")\n",
    "RF_training = pd.read_csv(\"/kaggle/input/cs4780-spring-2023-kaggle-competition/RF_train.csv\")\n",
    "RH_training = pd.read_csv(\"/kaggle/input/cs4780-spring-2023-kaggle-competition/RH_train.csv\")\n",
    "datasets = [LF_training,LH_training,RF_training,RH_training]\n",
    "labels = ['LF','LH','RF','RH']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b27c0a",
   "metadata": {
    "papermill": {
     "duration": 0.005637,
     "end_time": "2023-05-12T04:16:13.360060",
     "exception": false,
     "start_time": "2023-05-12T04:16:13.354423",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Preprocessing below for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c98f69a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T04:16:13.374135Z",
     "iopub.status.busy": "2023-05-12T04:16:13.373678Z",
     "iopub.status.idle": "2023-05-12T04:16:13.412661Z",
     "shell.execute_reply": "2023-05-12T04:16:13.411506Z"
    },
    "papermill": {
     "duration": 0.049501,
     "end_time": "2023-05-12T04:16:13.415415",
     "exception": false,
     "start_time": "2023-05-12T04:16:13.365914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_sets = []\n",
    "for df, label in zip(datasets,labels):\n",
    "    df = df.fillna(0)\n",
    "    y = df[label]\n",
    "    df = df.drop(['id','dob',label,'gait','Gait','forceplate_date'], axis=1)\n",
    "    df.replace('Not able to trot',-1, inplace = True)\n",
    "    df.replace('Not able to walk',-1, inplace = True)\n",
    "    df.replace('no data', 0, inplace = True)\n",
    "    df.replace('no valid trials', 0, inplace = True)\n",
    "\n",
    "    training_sets.append([df,y])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565a04c8",
   "metadata": {
    "papermill": {
     "duration": 0.005545,
     "end_time": "2023-05-12T04:16:13.426869",
     "exception": false,
     "start_time": "2023-05-12T04:16:13.421324",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Code that trains a model given a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55d00041",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T04:16:13.440922Z",
     "iopub.status.busy": "2023-05-12T04:16:13.440480Z",
     "iopub.status.idle": "2023-05-12T04:16:13.447876Z",
     "shell.execute_reply": "2023-05-12T04:16:13.446640Z"
    },
    "papermill": {
     "duration": 0.017799,
     "end_time": "2023-05-12T04:16:13.450661",
     "exception": false,
     "start_time": "2023-05-12T04:16:13.432862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def TrainModelSingleInstance(dataset,clf): \n",
    "    X,y = dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_training_pred = clf.predict(X_train)\n",
    "    training_accuracy = accuracy_score(y_train,y_training_pred)\n",
    "    y_testing_pred = clf.predict(X_test)\n",
    "    testing_accuracy = accuracy_score(y_test,y_testing_pred)\n",
    "    return training_accuracy,testing_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07444adc",
   "metadata": {
    "papermill": {
     "duration": 0.007117,
     "end_time": "2023-05-12T04:16:13.463712",
     "exception": false,
     "start_time": "2023-05-12T04:16:13.456595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Trains model with $k$ different training sets. Provides a rough expectation for model performance over $\\frac{1}{n}\\sum_{n=1}^{k} h_i(x) $ instead of just one instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76e2ae73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T04:16:13.478547Z",
     "iopub.status.busy": "2023-05-12T04:16:13.478121Z",
     "iopub.status.idle": "2023-05-12T04:16:13.485943Z",
     "shell.execute_reply": "2023-05-12T04:16:13.484620Z"
    },
    "papermill": {
     "duration": 0.018517,
     "end_time": "2023-05-12T04:16:13.488926",
     "exception": false,
     "start_time": "2023-05-12T04:16:13.470409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#printing version \n",
    "# def TrainModel(dataset,clf,iter):\n",
    "#     training_accuracy = 0\n",
    "#     testing_accuracy = 0\n",
    "#     for i in range(iter): \n",
    "#         x,y = TrainModelSingleInstance(dataset,clf)\n",
    "#         training_accuracy += x\n",
    "#         testing_accuracy += y\n",
    "#     training_accuracy = training_accuracy / iter\n",
    "#     testing_accuracy = testing_accuracy / iter\n",
    "#     string1 = \"The training accuracy_score is \" + str(training_accuracy) \n",
    "#     string2 = \"The testing accuracy_score \" + str(testing_accuracy)\n",
    "#     print(string1)\n",
    "#     print(string2)\n",
    "def TrainModel(dataset,clf,k):\n",
    "    training_accuracy = 0\n",
    "    testing_accuracy = 0\n",
    "    for i in range(k): \n",
    "        x,y = TrainModelSingleInstance(dataset,clf)\n",
    "        training_accuracy += x\n",
    "        testing_accuracy += y\n",
    "    training_accuracy = training_accuracy / k\n",
    "    testing_accuracy = testing_accuracy / k\n",
    "    return training_accuracy, testing_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102a6b1f",
   "metadata": {
    "papermill": {
     "duration": 0.005814,
     "end_time": "2023-05-12T04:16:13.501855",
     "exception": false,
     "start_time": "2023-05-12T04:16:13.496041",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Used to compare performance of classifiers over the dataset (name, classifier are now deleted from notebook)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a6ce48a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T04:16:13.516214Z",
     "iopub.status.busy": "2023-05-12T04:16:13.515333Z",
     "iopub.status.idle": "2023-05-12T04:16:13.522664Z",
     "shell.execute_reply": "2023-05-12T04:16:13.521489Z"
    },
    "papermill": {
     "duration": 0.017448,
     "end_time": "2023-05-12T04:16:13.525405",
     "exception": false,
     "start_time": "2023-05-12T04:16:13.507957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def TrainAllClassifiers(df):\n",
    "    best_accuracy = 0 \n",
    "    training_accuracy = 0\n",
    "    best_name = None \n",
    "    for name,classifier in zip(names,classifiers): \n",
    "        train,cur_accuracy = TrainModel(df,classifier,50)\n",
    "        best_accuracy = max(cur_accuracy,best_accuracy)\n",
    "        if best_accuracy == cur_accuracy: \n",
    "            best_name = name \n",
    "            training_accuracy = train\n",
    "    print(\"The best model is\" +best_name + \"with\" + str(best_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ff9fea",
   "metadata": {
    "papermill": {
     "duration": 0.005438,
     "end_time": "2023-05-12T04:16:13.536854",
     "exception": false,
     "start_time": "2023-05-12T04:16:13.531416",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "After Adaboost performed as the best classifier, Using Grid Search for hyperparameter tuning of $n\\_estimators$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbef5f53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T04:16:13.551189Z",
     "iopub.status.busy": "2023-05-12T04:16:13.550757Z",
     "iopub.status.idle": "2023-05-12T04:16:50.520634Z",
     "shell.execute_reply": "2023-05-12T04:16:50.519293Z"
    },
    "papermill": {
     "duration": 36.985256,
     "end_time": "2023-05-12T04:16:50.528350",
     "exception": false,
     "start_time": "2023-05-12T04:16:13.543094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.836364 using {'n_estimators': 100}\n",
      "0.763636 (0.078203) with: {'n_estimators': 10}\n",
      "0.772727 (0.064282) with: {'n_estimators': 50}\n",
      "0.836364 (0.061658) with: {'n_estimators': 100}\n",
      "0.827273 (0.066804) with: {'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 50, 100, 500]\n",
    "# grid['learning_rate'] = [1.0]\n",
    "# grid['learning_rate'] =  [1,1.5,2,2.5,3,3.5]\n",
    "\n",
    "# define the evaluation procedure\n",
    "model = AdaBoostClassifier(n_estimators = 500)\n",
    "\n",
    "# define the grid search procedure\n",
    "grid_search = GridSearchCV(model, grid)\n",
    "\n",
    "\n",
    "# execute the grid search\n",
    "X,y = training_sets[3]\n",
    "grid_result = grid_search.fit(X, y)\n",
    "\n",
    "# summarize the best score and configuration\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# summarize all scores that were evaluated\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e47d724",
   "metadata": {
    "papermill": {
     "duration": 0.005557,
     "end_time": "2023-05-12T04:16:50.540097",
     "exception": false,
     "start_time": "2023-05-12T04:16:50.534540",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Pre-processing of testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d90ad700",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T04:16:50.553671Z",
     "iopub.status.busy": "2023-05-12T04:16:50.553243Z",
     "iopub.status.idle": "2023-05-12T04:16:50.757112Z",
     "shell.execute_reply": "2023-05-12T04:16:50.755560Z"
    },
    "papermill": {
     "duration": 0.214153,
     "end_time": "2023-05-12T04:16:50.760077",
     "exception": false,
     "start_time": "2023-05-12T04:16:50.545924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LF_testing = pd.read_csv(\"/kaggle/input/cs4780-spring-2023-kaggle-competition/LF_test.csv\").fillna(0)\n",
    "LH_testing = pd.read_csv(\"/kaggle/input/cs4780-spring-2023-kaggle-competition/LH_test.csv\").fillna(0)\n",
    "RF_testing = pd.read_csv(\"/kaggle/input/cs4780-spring-2023-kaggle-competition/RF_test.csv\").fillna(0)\n",
    "RH_testing = pd.read_csv(\"/kaggle/input/cs4780-spring-2023-kaggle-competition/RH_test.csv\").fillna(0)\n",
    "\n",
    "df_id1 = LF_testing.copy(deep=True)[\"id\"].to_numpy()\n",
    "df_id2 = LH_testing.copy(deep=True)[\"id\"].to_numpy()\n",
    "df_id3 = RF_testing.copy(deep=True)[\"id\"].to_numpy()\n",
    "df_id4 = RH_testing.copy(deep=True)[\"id\"].to_numpy()\n",
    "test_datasets_pre = [LF_testing,LH_testing,RF_testing,RH_testing]\n",
    "test_datasets = []\n",
    "for df in test_datasets_pre:\n",
    "    df = df.fillna(0)\n",
    "    df = df.drop(['id','dob','gait','Gait','forceplate_date'], axis=1)\n",
    "    df.replace('Not able to trot',-1, inplace = True)\n",
    "    df.replace('Not able to walk',-1, inplace = True)\n",
    "    df.replace('no data', 0, inplace = True)\n",
    "    df.replace('no valid trials', 0, inplace = True)\n",
    "    test_datasets.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38cc30a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T04:16:50.774901Z",
     "iopub.status.busy": "2023-05-12T04:16:50.774498Z",
     "iopub.status.idle": "2023-05-12T04:17:18.612736Z",
     "shell.execute_reply": "2023-05-12T04:17:18.611412Z"
    },
    "papermill": {
     "duration": 27.849022,
     "end_time": "2023-05-12T04:17:18.615649",
     "exception": false,
     "start_time": "2023-05-12T04:16:50.766627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# models = [RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),AdaBoostClassifier(),SVC(gamma=2, C=1),AdaBoostClassifier()]\n",
    "models = [AdaBoostClassifier(n_estimators=500,learning_rate = 1.5),AdaBoostClassifier(n_estimators=500,learning_rate = 1.5),AdaBoostClassifier(n_estimators=500,learning_rate = 1.5),AdaBoostClassifier(n_estimators=500,learning_rate = 1.5)]\n",
    "\n",
    "predictions = []\n",
    "for model,test_dataset,training_set in zip(models,test_datasets,training_sets): \n",
    "    X_train, y_train  = training_set\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions.append(model.predict(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e74902a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T04:17:18.631338Z",
     "iopub.status.busy": "2023-05-12T04:17:18.630902Z",
     "iopub.status.idle": "2023-05-12T04:17:18.650432Z",
     "shell.execute_reply": "2023-05-12T04:17:18.649025Z"
    },
    "papermill": {
     "duration": 0.030865,
     "end_time": "2023-05-12T04:17:18.653364",
     "exception": false,
     "start_time": "2023-05-12T04:17:18.622499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LF_final = pd.DataFrame({'id': df_id1, 'LF':predictions[0]})\n",
    "LH_final = pd.DataFrame({'id': df_id2, 'LH':predictions[1]})\n",
    "RF_final = pd.DataFrame({'id': df_id3, 'RF':predictions[2]})\n",
    "RH_final = pd.DataFrame({'id': df_id4, 'RH':predictions[3]})\n",
    "\n",
    "LF_final.to_csv(\"/kaggle/working/LF_test_labels.csv\")\n",
    "LH_final.to_csv(\"/kaggle/working/LH_test_labels.csv\")\n",
    "RF_final.to_csv(\"/kaggle/working/RF_test_labels.csv\")\n",
    "RH_final.to_csv(\"/kaggle/working/RH_test_labels.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 84.744003,
   "end_time": "2023-05-12T04:17:19.783829",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-12T04:15:55.039826",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
